# SPDX-License-Identifier: Apache-2.0
# Copyright(c) 2021-2022 Wind River Systems, Inc.
- name: Deployment Manager Playbook
  hosts: all
  gather_facts: false
  become: false
  tasks:
    - set_fact:
        manager_chart: "{{ deployment_manager_chart | default('wind-river-cloud-platform-deployment-manager.tgz') }}"
    
    - set_fact:
        helm_chart_overrides: "{{ deployment_manager_overrides }}"
      when: deployment_manager_overrides is defined
    
    - set_fact:
        deploy_config: "{{ deployment_config }}"
        wait_for_dm_unlock: " {{ wait_for_dm_unlock| default(1) }}"
      when: deployment_config is defined

    - block:
      # Information to be used at final DM checks.
        - name: Get host name
          shell: |
            source /etc/platform/openrc; hostname
          register: get_host_name 

        - name: Get region name
          shell: |
            source /etc/platform/openrc; system show | awk '$2 ~ /^region_name/ { print $4}'
          register: get_region_name 

        - name: Show region and hostname
          debug:
            msg:
            - "hostname: {{get_host_name.stdout}}"
            - "region name: {{ get_region_name.stdout }}"

    - block:
      # Copy required files up to the target host if this playbook is being
      # executed remotely.

      - block:
        # Download a copy of the deployment manager helm chart if the location
        # supplied by the end user references a git repo.

        - name: Create A Temporary Download Directory
          tempfile:
            state: directory
          register: temp
          delegate_to: localhost

        - name: Download Deployment Manager Helm Chart From Repo
          shell: "git archive --remote={{ manager_chart }} | tar -x -C {{ temp.path }}"
          delegate_to: localhost

        - name: Reference Downloaded Helm Chart
          set_fact:
            manager_chart: "{{ lookup('fileglob', '{{ temp.path }}/docs/charts/wind-river-cloud-platform-deployment-manager-*.tgz', wantlist=true) | first }}"

        when: manager_chart | regex_search("^https|^git")

      - name: Upload Deployment Manager Helm Chart
        copy:
          src: "{{ manager_chart }}"
          dest: /home/{{ ansible_ssh_user }}/
          owner: "{{ ansible_ssh_user }}"
          group: root
          mode: 0644

      - set_fact:
          manager_chart: "/home/{{ ansible_ssh_user }}/{{ manager_chart | basename }}"

      - name: Upload Deployment Manager Helm Chart Overrides
        copy:
          src: "{{ helm_chart_overrides }}"
          dest: /home/{{ ansible_ssh_user }}/
          group: root
          mode: 0644
        when: helm_chart_overrides is defined

      - set_fact:
          helm_chart_overrides: "/home/{{ ansible_ssh_user }}/{{ helm_chart_overrides | basename }}"
        when: helm_chart_overrides is defined
      
      - name: Clean download directory
        file:
          path: "{{ temp.path }}"
          state: absent
        delegate_to: localhost
        when: temp.path is defined

      when: inventory_hostname != 'localhost'

    - name: Retrieve software version number
      shell: source /etc/build.info; echo $SW_VERSION
      register: sw_version_result

    - name: Fail if software version is not defined
      fail:
        msg: "SW_VERSION is missing in /etc/build.info"
      when: sw_version_result.stdout_lines|length == 0

    - name: Set software version and platform path
      set_fact:
        software_version: "{{ sw_version_result.stdout_lines[0] }}"
        platform_path: /opt/platform

    - name: Set config path facts
      set_fact:
        config_permdir: "{{ platform_path + '/config/' + software_version }}"

    - name: Mark the bootstrap as finalized
      file:
        path: "{{ config_permdir }}/.bootstrap_finalized"
        state: touch
      become: yes

    # Check if DM already exists in either helmv2 or helmv3
    - name: Get list of releases in helmv2
      command: >-
        /usr/local/sbin/helmv2-cli -- helm list --output json
      environment:
        KUBECONFIG: "/etc/kubernetes/admin.conf"
      ignore_errors: yes
      register: helmv2_releases

    - name: Query for DM release in helmv2
      shell: |
        grep -iq '"name":"deployment-manager"' <<< {{ helmv2_releases.stdout_lines }}
      ignore_errors: yes
      register: helmv2_dm_exists

    - name: Get list of releases in helmv3
      command: >-
        /usr/sbin/helm list --output json
      environment:
        KUBECONFIG: "/etc/kubernetes/admin.conf"
      ignore_errors: yes
      register: helmv3_releases

    - name: Query for DM release in helmv3
      shell: |
        grep -iq '"name":"deployment-manager"' <<< {{ helmv3_releases.stdout_lines }}
      ignore_errors: yes
      register: helmv3_dm_exists

    # Follow a different reinstallation procedure if DM is installed in helmv2
    - block:
      - name: Get armada pod name
        command: >-
          kubectl get pods -n armada -o custom-columns=NAME:metadata.name --no-headers
        environment:
          KUBECONFIG: "/etc/kubernetes/admin.conf"
        register: armada_pod

      - name: Show armada pod
        debug:
          msg:
          - "armada pod ID: {{ armada_pod.stdout }}"

      - name: Copy files into tiller container if using helmv2
        command: "{{ item }}"
        with_items:
          - kubectl -n armada cp
            {{ manager_chart }}
            {{ armada_pod.stdout }}:/tmp/.
            -c tiller
          - kubectl -n armada cp
            {% if helm_chart_overrides is defined %}{{ helm_chart_overrides }}{% endif %}
            {{ armada_pod.stdout }}:/tmp/.
            -c tiller
        environment:
          KUBECONFIG: "/etc/kubernetes/admin.conf"

      - name: Reinstall Deployment Manager (helmv2)
        command: >-
          /usr/local/sbin/helmv2-cli -- helm upgrade
          --install deployment-manager
          --values /tmp/{{ helm_chart_overrides | basename }}
          /tmp/{{ manager_chart | basename }}
        environment:
          KUBECONFIG: "/etc/kubernetes/admin.conf"

      when: helmv2_dm_exists.rc == 0

    # Remove v1 webhook and webhook service
    - block:
      - name: Search webhook configurations for v1
        shell: |
          kubectl get ValidatingWebhookConfigurations validating-webhook-configuration --no-headers | awk 'NR == 1 { print $1 }'
        environment:
          KUBECONFIG: "/etc/kubernetes/admin.conf"
        ignore_errors: yes
        register: validation_webhook

      - name: Query for validating webhook configuration
        shell: |
          grep -iq 'validating-webhook-configuration' <<< {{ validation_webhook.stdout_lines }}
        ignore_errors: yes
        register: webhook_config_exists

      - name: Delete validating webhook configuration
        shell: |
          kubectl delete ValidatingWebhookConfigurations validating-webhook-configuration
        environment:
          KUBECONFIG: "/etc/kubernetes/admin.conf"
        when: webhook_config_exists.rc == 0

      - name: Search webhook service for v1
        shell: |
          kubectl get svc webhook-server-service -n platform-deployment-manager --no-headers | awk 'NR == 1 { print $1 }'
        environment:
          KUBECONFIG: "/etc/kubernetes/admin.conf"
        register: webhook_service

      - name: Query for webhook-server-service
        shell: |
          grep -iq 'webhook-server-service' <<< {{ webhook_service.stdout_lines }}
        ignore_errors: yes
        register: webhook_service_exists

      - name: Delete webhook-server-service
        shell: |
          kubectl delete svc webhook-server-service -n platform-deployment-manager
        environment:
          KUBECONFIG: "/etc/kubernetes/admin.conf"
        when: webhook_service_exists.rc == 0

      when: helmv2_dm_exists.rc != 0

    - name: Install Deployment Manager
      shell: KUBECONFIG=/etc/kubernetes/admin.conf /usr/sbin/helm upgrade --install deployment-manager {% if helm_chart_overrides is defined %}--values {{ helm_chart_overrides }}{% endif %} {{ manager_chart }}
      when: helmv2_dm_exists.rc != 0

    # Restart Deployment Manager if it was reinstalled
    - block:
      - name: Search for the pod of the Deployment Manager
        shell: |
          kubectl -n platform-deployment-manager get pods | awk 'NR == 2 { print $1 }'
        environment:
          KUBECONFIG: "/etc/kubernetes/admin.conf"
        register: deployment_manager_pod_name

      - debug:
          msg: "{{ deployment_manager_pod_name.stdout }}"

      - name: Restart Deployment Manager if reinstalled
        command: >-
          kubectl -n platform-deployment-manager delete pods {{ deployment_manager_pod_name.stdout }}
        environment:
          KUBECONFIG: "/etc/kubernetes/admin.conf"
        when: deployment_manager_pod_name.stdout

      when: helmv2_dm_exists.rc == 0 or helmv3_dm_exists.rc == 0

    - name: Wait for Deployment Manager to be ready
      shell: KUBECONFIG=/etc/kubernetes/admin.conf /bin/kubectl wait --namespace=platform-deployment-manager --for=condition=Ready pods --selector control-plane=controller-manager --timeout=60s
      register: wait_for_deployment_manager

    - block:
        - name: Upload Deployment Configuration File
          copy:
            src: "{{ deploy_config }}"
            dest: /home/{{ ansible_ssh_user }}/deployment-config.yaml
            owner: "{{ ansible_ssh_user }}"
            group: root
            mode: 0755
          when: inventory_hostname != 'localhost'

        - set_fact:
            deploy_config: "/home/{{ ansible_ssh_user }}/deployment-config.yaml"
          when: inventory_hostname != 'localhost'

        - wait_for:
            # Pause for an arbitrary amount of time to allow the deployment
            # manager to come up and download its certificates.  It needs to
            # restart during this process so the webhooks may not be ready when
            # we apply the config in the next steps.
            timeout: 10
            msg: Waiting for the Deployment Manager validation webhooks to start

        - name: Apply Deployment Configuration File
          shell: KUBECONFIG=/etc/kubernetes/admin.conf /bin/kubectl apply -f {{ deploy_config }}
          register: apply_deploy_config
          retries: 5
          delay: 10
          until: apply_deploy_config.rc == 0

      when: deploy_config is defined

    # Create default registry key in platform-deployment-manager for future image pulls
    - name: Get platform-deployment-manager namespace default registry key
      command: >-
        kubectl --kubeconfig=/etc/kubernetes/admin.conf get secret default-registry-key --namespace=platform-deployment-manager
      failed_when: false
      register: get_dm_default_registry_key

    - name: Copy default-registry-key to platform-deployment-manager namespace
      shell: >-
        kubectl get secret default-registry-key --namespace=kube-system -o yaml
        | sed 's/namespace: kube-system/namespace: platform-deployment-manager/'
        | kubectl apply --namespace=platform-deployment-manager -f -
      environment:
        KUBECONFIG: "/etc/kubernetes/admin.conf"
      when: get_dm_default_registry_key.stdout == ""

    - block:
        - wait_for:
            # waiting task after apply config to avoid failures getting info
            timeout: 5
            msg: Waiting after apply DM config

        # If unlock task is triggered, is highly probable that config applied is ok. 
        - name: Wait until unlock task triggered
          shell: |
            source /etc/platform/openrc;
            system host-show "{{ get_host_name.stdout}}" | awk '$2 ~ /^task/ {print $4}'
          register: get_show_task_status
          until: ("Unlocking" in get_show_task_status.stdout)
          retries: 800
          delay: "{{wait_for_dm_unlock}}"
          ignore_errors: yes

        - name: Show waiting unlock
          debug:
            msg:
            - "waiting: {{get_show_task_status.stdout}}"
            - "waiting: {{get_show_task_status.stderr}}"
            
        - name: Retrieve kubectl resources reconciled status
          shell: >-
            kubectl -n deployment get datanetworks,hostprofiles,hosts,platformnetworks,systems,ptpinstances,ptpinterfaces |
            awk '$NF ~ /^false/ {print}'
          environment:
            KUBECONFIG: "/etc/kubernetes/admin.conf"
          register: get_recon_status_pre_unlock

        - name: Show unreconciled resources
          debug:
            msg:
            - "recon: {{get_recon_status_pre_unlock.stdout}}"

        #get pod name and error logs
        - name: Get dm pod name
          shell: >-
            kubectl -n platform-deployment-manager get pods |
            awk '$1 ~ /^platform-deployment-manager/ {print $1}'
          environment:
            KUBECONFIG: "/etc/kubernetes/admin.conf"
          register: get_dm_pod_name

        - name: Retrieve dm logs
          shell: >-
            kubectl -n platform-deployment-manager logs "{{ get_dm_pod_name.stdout }}" |
            awk '(/ERROR/ && !/validation/ && !/waiting/ && !(seen[$10, $NF]++)) {print}'
          environment:
            KUBECONFIG: "/etc/kubernetes/admin.conf"
          register: get_logs_pre_unlock

        - name: Show logs
          debug:
            msg:
            - "Pod log: {{get_logs_pre_unlock.stdout}}"
            - "err: {{get_logs_pre_unlock.stderr}}"

        - name: Output dm logs
          fail:
            msg:
              - "Fail waiting for host unlock to be triggered. It could be due to DM config errors"
              - "UNRECONCILED resources: {{get_recon_status_pre_unlock.stdout}}"
              - "{{get_logs_pre_unlock.stdout}}"
          register: fail_dm_logs
          when: ("Unlocking" not in get_show_task_status.stdout)

      when: (deploy_config is defined and "subcloud" in get_region_name.stdout)
